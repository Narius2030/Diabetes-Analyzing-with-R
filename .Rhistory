x = train,
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
#improve = 0.01,
trace = T,
plot = T
)
rf_fit <- tuneRF(
x = train,
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
rf_fit <- tuneRF(
x = train,
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = FALSE
)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = FALSE
)
model <- randomForest(BMI_Category ~ -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model <- randomForest(BMI_Category ~. -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
#sum(prediction==test$BMI_Category) / nrow(test) # The output is as shown below
accuracy <- mean(prediction == test$BMI_Category)
accuracy
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category ~. -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category~. -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category ~. -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=4)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
#sum(prediction==test$BMI_Category) / nrow(test) # The output is as shown below
accuracy <- mean(prediction == test$BMI_Category)
accuracy
sum(prediction==test$BMI_Category) / nrow(test) # The output is as shown below
accuracy <- mean(prediction == test$BMI_Category)
accuracy
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = FALSE
)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
set.seed(123)
samp <- sample(nrow(diabetes), 0.5 * nrow(diabetes))
train <- diabetes[samp, ]
test <- diabetes[-samp, ]
dim(train)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=4)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
#sum(prediction==test$BMI_Category) / nrow(test) # The output is as shown below
accuracy <- mean(prediction == test$BMI_Category)
accuracy
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
#sum(prediction==test$BMI_Category) / nrow(test) # The output is as shown below
accuracy <- mean(prediction == test$BMI_Category)
accuracy
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
set.seed(123)
samp <- sample(nrow(diabetes), 0.7 * nrow(diabetes))
train <- diabetes[samp, ]
test <- diabetes[-samp, ]
dim(train)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
#sum(prediction==test$BMI_Category) / nrow(test) # The output is as shown below
accuracy <- mean(prediction == test$BMI_Category)
accuracy
# Huấn luyện mô hình Random Forest
model <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf",metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 5),
search = "grid")
library(caret)
# Huấn luyện mô hình Random Forest
model <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf",metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 5),
search = "grid")
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model, test)
confusionMatrix(pred, test$BMI_Category)
sum(pred==test$BMI_Category) / nrow(test)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
accuracy <- mean(prediction == test$BMI_Category)
accuracy
accuracy <- mean(pred == test$BMI_Category)
accuracy
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model, test)
confusionMatrix(pred, test$BMI_Category)
pred
prediction <- predict(model, newdata = test)
#table(prediction, test$BMI_Category)
prediction
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
accuracy <- mean(prediction == test$BMI_Category)
accuracy
# Huấn luyện mô hình Random Forest
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf",metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 5),
search = "grid")
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, test)
table(pred, test$BMI_Category)
pred
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
pred
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
prediction
accuracy <- mean(pred == test$BMI_Category)
accuracy
# Đọc file CSV trực tiếp từ đường link
diabetes <- read_csv("https://drive.google.com/uc?id=15mjrv0LV2T6GWNdAuW-QhXVdtMkQALlh")
# Hiển thị dữ liệu
diabetes
str(diabetes)
library(ggplot2)
diabetes$BMI_Category <- cut(diabetes$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c("Underweight", "Normal", "Overweight", "Obese"))
ggplot(diabetes, aes(x = BMI_Category)) +
geom_bar(stat = "count") +
labs(title = "Distribution of BMI Categories", x = "BMI Category", y = "Count") +
theme_bw()
num_diabetes <- diabetes
num_diabetes$BMI_Category <- cut(num_diabetes$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c(0, 1, 2, 3))
num_diabetes$BMI_Category <- as.integer(num_diabetes$BMI_Category)
library(lattice)
library(reshape2)
# creating correlation matrix
corr_mat <- round(cor(num_diabetes),2)
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
# head(melted_corr_mat)
# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value)) + geom_tile() +
geom_text(aes(Var2, Var1, label = value), color = "white", size = 4)
set.seed(123)
samp <- sample(nrow(diabetes), 0.7 * nrow(diabetes))
train <- diabetes[samp, ]
test <- diabetes[-samp, ]
dim(train)
library(randomForest)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
accuracy <- mean(prediction == test$BMI_Category)
accuracy
library(caret)
# Huấn luyện mô hình Random Forest
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf",metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 5),
search = "grid")
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
prediction
accuracy <- mean(pred == test$BMI_Category)
accuracy
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
pred
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(prediction, test$BMI_Category)
pred
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
prediction
accuracy <- mean(pred == test$BMI_Category)
accuracy
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(prediction, test$BMI_Category)
pred
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
prediction
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
pred
# Đánh giá mô hình trên tập kiểm tra
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
prediction
accuracy <- mean(pred == test$BMI_Category)
accuracy
# Đọc file CSV trực tiếp từ đường link
diabetes <- read_csv("https://drive.google.com/uc?id=15mjrv0LV2T6GWNdAuW-QhXVdtMkQALlh")
library(readr)
# Đọc file CSV trực tiếp từ đường link
diabetes <- read_csv("https://drive.google.com/uc?id=15mjrv0LV2T6GWNdAuW-QhXVdtMkQALlh")
# Hiển thị dữ liệu
diabetes
str(diabetes)
library(ggplot2)
diabetes$BMI_Category <- cut(diabetes$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c("Underweight", "Normal", "Overweight", "Obese"))
ggplot(diabetes, aes(x = BMI_Category)) +
geom_bar(stat = "count") +
labs(title = "Distribution of BMI Categories", x = "BMI Category", y = "Count") +
theme_bw()
num_diabetes <- diabetes
num_diabetes$BMI_Category <- cut(num_diabetes$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c(0, 1, 2, 3))
num_diabetes$BMI_Category <- as.integer(num_diabetes$BMI_Category)
library(lattice)
renv::activate()
library(lattice)
library(reshape2)
# creating correlation matrix
corr_mat <- round(cor(num_diabetes),2)
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
# head(melted_corr_mat)
# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value)) + geom_tile() +
geom_text(aes(Var2, Var1, label = value), color = "white", size = 4)
set.seed(123)
samp <- sample(nrow(diabetes), 0.7 * nrow(diabetes))
train <- diabetes[samp, ]
test <- diabetes[-samp, ]
#Kiểm tra kích thước của tập dữ liệu huấn luyện và kiểm tra
dim(train)
library(randomForest)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=3)
model
accuracy <- mean(prediction == test$BMI_Category)
accuracy
library(caret)
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf",metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 5),
search = "grid")
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
prediction
accuracy <- mean(pred == test$BMI_Category)
accuracy
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:100) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$Species)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$Species)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "Lỗi")
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:100) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$BMI_Category)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$BMI_Category)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "Lỗi")
lines(error_test, type = "l", col = "red")
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:100) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$BMI_Category)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$BMI_Category)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "OOB error")
lines(error_test, type = "l", col = "red")
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:100) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$BMI_Category)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$BMI_Category)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "OOB error", xlab="Số cây trong rừng")
lines(error_test, type = "l", col = "red")
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 50, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
accuracy <- mean(prediction == test$BMI_Category)
accuracy
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 20, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
accuracy <- mean(prediction == test$BMI_Category)
accuracy
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:1000) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$BMI_Category)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$BMI_Category)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "OOB error", xlab="Số cây trong rừng")
lines(error_test, type = "l", col = "red")
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:100) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$BMI_Category)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$BMI_Category)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "OOB error", xlab="Số cây trong rừng")
lines(error_test, type = "l", col = "red")
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:100) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$BMI_Category)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$BMI_Category)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "OOB error", xlab="Số cây trong rừng")
lines(error_test, type = "l", col = "red")
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 60, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
accuracy <- mean(prediction == test$BMI_Category)
accuracy
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 10, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
prediction
accuracy <- mean(prediction == test$BMI_Category)
accuracy
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
#prediction
accuracy <- mean(prediction == test$BMI_Category)
accuracy
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf",metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 5),
search = "grid")
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
accuracy <- mean(pred == test$BMI_Category)
accuracy
