)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=3)
# Đọc file CSV trực tiếp từ đường link
diabetes <- read.csv("https://drive.google.com/uc?id=15mjrv0LV2T6GWNdAuW-QhXVdtMkQALlh")
# Hiển thị dữ liệu
diabetes
na_count<-colSums(sapply(diabetes,is.na))
na_count
diabetes_median <- diabetes %>%
mutate_all(~ ifelse(is.na(.), median(., na.rm = TRUE), .))
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
diabetes_median <- diabetes %>%
mutate_all(~ ifelse(is.na(.), median(., na.rm = TRUE), .))
diabetes_z <- (diabetes - colMeans(diabetes)) / apply(diabetes, 2, sd)
diabetes_z
melted_diabetes <- gather(diabetes_z, key = "Variable", value = "Z-score")
# Vẽ scatter plot cho tất cả các cột
ggplot(melted_diabetes, aes(x = Variable, y = `Z-score`, color = `Z-score`)) +
geom_point() +
labs(x = "Variable", y = "Z-score", title = "Scatter Plots of Z-scores") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Điều chỉnh góc và vị trí của chú thích trên trục x
# Lọc các giá trị Z-score mà tất cả đều nhỏ hơn 360
diabetes_filter <- diabetes[rowSums(apply(diabetes_z, 2, function(x) abs(x) < 700)) == ncol(diabetes_z), ]
# Hiển thị kích thước của bộ dữ liệu sau khi loại bỏ
cat("Còn lại số lượng hàng và cột là:", dim(diabetes_filter))
attach(diabetes_filter)
par(mfrow=c(2,4))
boxplot(Pregnancies~Outcome, main="No. of Pregnancies vs. Diabetes",
xlab="Outcome", ylab="Pregnancies",col="red")
boxplot(Glucose~Outcome, main="Glucose vs. Diabetes",
xlab="Outcome", ylab="Glucose",col="pink")
boxplot(BloodPressure~Outcome, main="Blood Pressure vs. Diabetes",
xlab="Outcome", ylab="Blood Pressure",col="green")
boxplot(SkinThickness~Outcome, main="Skin Thickness vs. Diabetes",
xlab="Outcome", ylab="Skin Thickness",col="orange")
boxplot(Insulin~Outcome, main="Insulin vs. Diabetes",
xlab="Outcome", ylab="Insulin",col="yellow")
boxplot(BMI~Outcome, main="BMI vs. Diabetes",
xlab="Outcome", ylab="BMI",col="purple")
boxplot(DiabetesPedigreeFunction~Outcome, main="Diabetes Pedigree Function vs. Diabetes", xlab="Outcome", ylab="DiabetesPedigreeFunction",col="lightgreen")
boxplot(Age~Outcome, main="Age vs. Diabetes",
xlab="Outcome", ylab="Age",col="lightblue")
box(which = "outer", lty = "solid")
diabetes_filter$BMI_Category <- cut(diabetes_filter$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c("Underweight", "Normal", "Overweight", "Obese"))
ggplot(diabetes_filter, aes(x = BMI_Category)) +
geom_bar(stat = "count") +
labs(title = "Distribution of BMI Categories", x = "BMI Category", y = "Count") +
theme_bw()
num_diabetes <- diabetes_filter
num_diabetes$BMI_Category <- cut(diabetes_filter$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c(0, 1, 2, 3))
num_diabetes$BMI_Category <- as.integer(num_diabetes$BMI_Category)
library(lattice)
library(reshape2)
# creating correlation matrix
corr_mat <- round(cor(num_diabetes),2)
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
# head(melted_corr_mat)
# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value)) + geom_tile() +
geom_text(aes(Var2, Var1, label = value), color = "white", size = 4)
set.seed(123)
samp <- sample(nrow(diabetes_filter), 0.7 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
#Kiểm tra kích thước của tập dữ liệu huấn luyện và kiểm tra
dim(train)
library(randomForest)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, ntree = 100, mtry=3)
model
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
set.seed(123)
samp <- sample(nrow(diabetes_filter), 0.5 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
set.seed(12)
samp <- sample(nrow(diabetes_filter), 0.5 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
set.seed(12)
samp <- sample(nrow(diabetes_filter), 0.7 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
set.seed(456)
samp <- sample(nrow(diabetes_filter), 0.7 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
set.seed(456)
samp <- sample(nrow(diabetes_filter), 0.6 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 50, mtry=3)
model
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
library(tuneRF)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 4,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:100) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$BMI_Category)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$BMI_Category)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "OOB error", xlab="Số cây trong rừng")
lines(error_test, type = "l", col = "red")
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.2,
improve = 0.01,
trace = T,
plot = T
)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
set.seed(456)
samp <- sample(nrow(diabetes_filter), 0.8 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
set.seed(456)
samp <- sample(nrow(diabetes_filter), 0.5 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
set.seed(122)
samp <- sample(nrow(diabetes_filter), 0.5 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
set.seed(12)
samp <- sample(nrow(diabetes_filter), 0.5 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
#Kiểm tra kích thước của tập dữ liệu huấn luyện và kiểm tra
dim(train)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=4)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
renv::activate()
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
# Đọc file CSV trực tiếp từ đường link
diabetes <- read.csv("https://drive.google.com/uc?id=15mjrv0LV2T6GWNdAuW-QhXVdtMkQALlh")
# Hiển thị dữ liệu
diabetes
na_count<-colSums(sapply(diabetes,is.na))
na_count
diabetes_median <- diabetes %>%
mutate_all(~ ifelse(is.na(.), median(., na.rm = TRUE), .))
diabetes_z <- (diabetes - colMeans(diabetes)) / apply(diabetes, 2, sd)
diabetes_z
melted_diabetes <- gather(diabetes_z, key = "Variable", value = "Z-score")
# Vẽ scatter plot cho tất cả các cột
ggplot(melted_diabetes, aes(x = Variable, y = `Z-score`, color = `Z-score`)) +
geom_point() +
labs(x = "Variable", y = "Z-score", title = "Scatter Plots of Z-scores") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Điều chỉnh góc và vị trí của chú thích trên trục x
# Lọc các giá trị Z-score mà tất cả đều nhỏ hơn 360
diabetes_filter <- diabetes[rowSums(apply(diabetes_z, 2, function(x) abs(x) < 700)) == ncol(diabetes_z), ]
# Hiển thị kích thước của bộ dữ liệu sau khi loại bỏ
cat("Còn lại số lượng hàng và cột là:", dim(diabetes_filter))
attach(diabetes_filter)
par(mfrow=c(2,4))
boxplot(Pregnancies~Outcome, main="No. of Pregnancies vs. Diabetes",
xlab="Outcome", ylab="Pregnancies",col="red")
boxplot(Glucose~Outcome, main="Glucose vs. Diabetes",
xlab="Outcome", ylab="Glucose",col="pink")
boxplot(BloodPressure~Outcome, main="Blood Pressure vs. Diabetes",
xlab="Outcome", ylab="Blood Pressure",col="green")
boxplot(SkinThickness~Outcome, main="Skin Thickness vs. Diabetes",
xlab="Outcome", ylab="Skin Thickness",col="orange")
boxplot(Insulin~Outcome, main="Insulin vs. Diabetes",
xlab="Outcome", ylab="Insulin",col="yellow")
boxplot(BMI~Outcome, main="BMI vs. Diabetes",
xlab="Outcome", ylab="BMI",col="purple")
boxplot(DiabetesPedigreeFunction~Outcome, main="Diabetes Pedigree Function vs. Diabetes", xlab="Outcome", ylab="DiabetesPedigreeFunction",col="lightgreen")
boxplot(Age~Outcome, main="Age vs. Diabetes",
xlab="Outcome", ylab="Age",col="lightblue")
box(which = "outer", lty = "solid")
min_max_scaler <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
diabetes_filter <- as.data.frame(lapply(diabetes_filter, min_max_scaler))
diabetes_filter
diabetes_filter$BMI_Category <- cut(diabetes_filter$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c("Underweight", "Normal", "Overweight", "Obese"))
ggplot(diabetes_filter, aes(x = BMI_Category)) +
geom_bar(stat = "count") +
labs(title = "Distribution of BMI Categories", x = "BMI Category", y = "Count") +
theme_bw()
min_max_scaler <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
diabetes_scale <- as.data.frame(lapply(diabetes_filter, min_max_scaler))
# Đọc file CSV trực tiếp từ đường link
diabetes <- read.csv("https://drive.google.com/uc?id=15mjrv0LV2T6GWNdAuW-QhXVdtMkQALlh")
# Hiển thị dữ liệu
diabetes
na_count<-colSums(sapply(diabetes,is.na))
na_count
fill_mode <- function(x) {
mode_val <- names(sort(table(x), decreasing = TRUE))[1]
x[is.na(x)] <- mode_val
return(x)
}
diabetes_mode <- diabetes %>%
mutate_all(fill_mode)
diabetes_z <- (diabetes - colMeans(diabetes)) / apply(diabetes, 2, sd)
diabetes_z
melted_diabetes <- gather(diabetes_z, key = "Variable", value = "Z-score")
# Vẽ scatter plot cho tất cả các cột
ggplot(melted_diabetes, aes(x = Variable, y = `Z-score`, color = `Z-score`)) +
geom_point() +
labs(x = "Variable", y = "Z-score", title = "Scatter Plots of Z-scores") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Điều chỉnh góc và vị trí của chú thích trên trục x
# Lọc các giá trị Z-score mà tất cả đều nhỏ hơn 360
diabetes_filter <- diabetes[rowSums(apply(diabetes_z, 2, function(x) abs(x) < 700)) == ncol(diabetes_z), ]
# Hiển thị kích thước của bộ dữ liệu sau khi loại bỏ
cat("Còn lại số lượng hàng và cột là:", dim(diabetes_filter))
attach(diabetes_filter)
par(mfrow=c(2,4))
boxplot(Pregnancies~Outcome, main="No. of Pregnancies vs. Diabetes",
xlab="Outcome", ylab="Pregnancies",col="red")
boxplot(Glucose~Outcome, main="Glucose vs. Diabetes",
xlab="Outcome", ylab="Glucose",col="pink")
boxplot(BloodPressure~Outcome, main="Blood Pressure vs. Diabetes",
xlab="Outcome", ylab="Blood Pressure",col="green")
boxplot(SkinThickness~Outcome, main="Skin Thickness vs. Diabetes",
xlab="Outcome", ylab="Skin Thickness",col="orange")
boxplot(Insulin~Outcome, main="Insulin vs. Diabetes",
xlab="Outcome", ylab="Insulin",col="yellow")
boxplot(BMI~Outcome, main="BMI vs. Diabetes",
xlab="Outcome", ylab="BMI",col="purple")
boxplot(DiabetesPedigreeFunction~Outcome, main="Diabetes Pedigree Function vs. Diabetes", xlab="Outcome", ylab="DiabetesPedigreeFunction",col="lightgreen")
boxplot(Age~Outcome, main="Age vs. Diabetes",
xlab="Outcome", ylab="Age",col="lightblue")
box(which = "outer", lty = "solid")
min_max_scaler <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
diabetes_scale <- as.data.frame(lapply(diabetes_filter, min_max_scaler))
diabetes_scale
diabetes_filter$BMI_Category <- cut(diabetes_filter$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c("Underweight", "Normal", "Overweight", "Obese"))
ggplot(diabetes_filter, aes(x = BMI_Category)) +
geom_bar(stat = "count") +
labs(title = "Distribution of BMI Categories", x = "BMI Category", y = "Count") +
theme_bw()
num_diabetes <- diabetes_filter
num_diabetes$BMI_Category <- cut(diabetes_filter$BMI,
breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c(0, 1, 2, 3))
num_diabetes$BMI_Category <- as.integer(num_diabetes$BMI_Category)
library(lattice)
library(reshape2)
# creating correlation matrix
corr_mat <- round(cor(num_diabetes),2)
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
# head(melted_corr_mat)
# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value)) + geom_tile() +
geom_text(aes(Var2, Var1, label = value), color = "white", size = 4)
set.seed(12)
samp <- sample(nrow(diabetes_filter), 0.5 * nrow(diabetes_filter))
train <- diabetes_filter[samp, ]
test <- diabetes_filter[-samp, ]
#Kiểm tra kích thước của tập dữ liệu huấn luyện và kiểm tra
dim(train)
library(randomForest)
rf_fit <- tuneRF(
x = train[,-9],
y = train$BMI_Category,
metric = "OOBAcc",
ntreeTry = 100,
mtryStart = 3,
stepFactor = 1.5,
improve = 0.01,
trace = T,
plot = T
)
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()
error_test <- c()
for (ntree in 1:100) {
# Huấn luyện mô hình
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = ntree, mtry=3)
# Tính lỗi ra ngoài túi
error_out_of_bag[ntree] <- mean(predict(model, train) != train$BMI_Category)
# Tính lỗi kiểm tra
error_test[ntree] <- mean(predict(model, test) != test$BMI_Category)
}
# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "blue", ylab = "OOB error", xlab="Số cây trong rừng")
lines(error_test, type = "l", col = "red")
model <- randomForest(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome -Pregnancies, data = train, ntree = 100, mtry=3)
model
prediction <- predict(model, newdata = test)
table(prediction, test$BMI_Category)
accuracy <- mean(prediction == test$BMI_Category)
accuracy
library(caret)
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf", metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 5),
search = "grid")
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
accuracy <- mean(pred == test$BMI_Category)
accuracy
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf", metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 6),
search = "grid")
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
accuracy <- mean(pred == test$BMI_Category)
accuracy
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf", metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 100),
search = "grid")
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf", metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 10),
search = "grid")
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
accuracy <- mean(pred == test$BMI_Category)
accuracy
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf", metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 20),
search = "grid")
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf", metric = "Accuracy" ,trControl = trainControl(
method = "cv",
number = 20,
search = "grid"))
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
accuracy <- mean(pred == test$BMI_Category)
accuracy
model_cv <- train(BMI_Category ~ . -DiabetesPedigreeFunction -Age -Outcome, data = train, method = "rf", metric = "Accuracy", trControl = trainControl(method = "cv", number = 20, search = "grid"))
pred <- predict(model_cv, newdata=test)
table(pred, test$BMI_Category)
accuracy <- mean(pred == test$BMI_Category)
accuracy
