<link rel="stylesheet" type="text/css" href="styles.css">
<br>
<img src="https://fit.hcmute.edu.vn/Resources/Images/SubDomain/fit/HCMUTE-fit.png" alt="ảnh đồ án" class="custom-image-class">
<br>
<br>
<div>
<h1 style="color:red; text-align: center;">**NHÓM 7 DỮ LIỆU VỀ TIỂU ĐƯỜNG **</h1>
<h1 style="color:black; text-align: center;">**Thăm dò tập dữ liệu Pima Indian Diabetes **</h1>
<h4 style="text-align: center;">*date: 2023-12-13*</h4>
</div>
<br>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## I.Exploring the dataset
## Installing module
```{r}
#install.packages('reader')
#install.packages("lattice")
#install.packages("reshape2")
#install.packages('ggplot2')
```

## Exploring data

```{r}
library(reader)

# Đọc file CSV trực tiếp từ đường link
diabetes <- read.csv("https://drive.google.com/uc?id=15mjrv0LV2T6GWNdAuW-QhXVdtMkQALlh")
# Hiển thị dữ liệu
head(diabetes)
```

### Overall of dataset: dữ liệu y tế và nhân khẩu học của phụ nữ để dự đoán bệnh tiểu đường

Bộ dữ liệu này chứa thông tin về 769 phụ nữ và bao gồm nhiều thuộc tính liên quan đến sức khỏe. Dưới đây là tổng quan ngắn gọn về các cột:

* Mang thai: Số lần người phụ nữ đã mang thai.

* Glucose: Nồng độ glucose trong huyết tương của người phụ nữ.

* Huyết áp: Đo huyết áp.

* Độ dày của da: Độ dày của nếp gấp da ở cơ tam đầu.

* Insulin: Nồng độ insulin trong máu.

* BMI (Chỉ số khối cơ thể): Thước đo lượng mỡ trong cơ thể dựa trên chiều cao và cân nặng.

* Chức năng phả hệ bệnh tiểu đường: Một chức năng cho thấy khả năng mắc bệnh tiểu đường dựa trên tiền sử gia đình.

* Tuổi: Tuổi của người phụ nữ.

* Kết quả: Biến mục tiêu cho biết người phụ nữ có mắc bệnh tiểu đường hay không (1 đối với bệnh nhân tiểu đường, 0 đối với người không mắc bệnh tiểu đường).

#### Structure of dataset

```{r}
str(diabetes)
```


Ta có thể thấy:

- Chỉ có 2 thuộc tính BMI và DiabetesPedigreeFunction là kiểu số thực, còn lại là int

- Tổng có 768 dòng và 9 cột

#### Summary of statistic

```{r}
summary(diabetes)
```


Ta có thể thấy:

- Cột SkinThickness, Insulin có 1% điểm dữ liệu bằng 0 (vì Min=0)

- Cột Outcome có 75% điểm dữ liệu < 1, chứng tỏ tỉ lệ mắc bệnh tiểu đường thấp

#### Data visualization of distribution attributes

##### Distribution of Age, Pregnancies, Glucose and Outcome

```{r}
#install.packages("cowplot")
#install.packages("gridExtra")
library(ggplot2)
library(cowplot)
library(gridExtra)
```

```{r}
par(mfrow=c(1,4))
# Boxplot cho Age
boxplot(diabetes$Age,
        col="#ff0066",
        main="Boxplot for Age")

# Boxplot cho Pregnancies
boxplot(diabetes$Pregnancies,
        col="yellow",
        main="Boxplot for Pregnancy")

# Boxplot cho Pregnancies
barplot(table(diabetes$Outcome), main = "Barplot of Out come", xlab = "Outcome", ylab="Count")

plot(density(diabetes$Glucose),
     col="yellow",
     main="Density Plot for Glucose",
     xlab="Glucose",
     ylab="Density")
polygon(density(diabetes$Glucose),
        col="#ccff66")

box(which = "outer", lty = "solid")
```

Ta có thể thấy:

* Từ boxplot về độ tuổi, cho thấy rằng phụ nữ trong tập dữ liệu tập trung chủ yếu ở khoảng 25-41 tuổi

* Từ boxplot về số lần mang thai, cho thấy rằng phụ nữ chủ yếu có số lần mang thai từ 1-6 lần

* Từ boxplot giữa nồng độ glucose và kết quả, những người không bệnh sẽ có nồng độ glucose thấp hơn nhóm bị bệnh; nhóm không bệnh có nồng độ glucose tập trung khoảng 99-130 mg/dl, còn nhóm bị bệnh khoảng 130-170 mg/dl


##### The correlation of Glucose, Outcome and Insulin

```{r}
par(mfrow=c(1,2))
plot(diabetes$Insulin, diabetes$Glucose, xlab="Insulin", ylab="Glucose", type='p', col=c("red"), pch=20, main="Tương quan giữa Glucose và Insulin")

# Boxplot cho Outcome và Glucose theo người mắc bệnh và không
diabetes_groups <- cut(diabetes$Outcome, c(-Inf, 0, Inf), labels = c("Không bệnh", "Bệnh"))
boxplot(diabetes$Glucose~diabetes_groups, xlab="Outcome", ylab="Glucose (mg/dl)", main="Tỉ lệ giữa Glucose và Outcome", col="pink")

box(which="outer", lty="solid")
```

Ta có thể thấy:

* Lượng Insulin càng ít thì lượng đường Glucose càng cao, do Insulin có khả nào chuyển hóa đường nhưng những người mắc bệnh tiểu đường thì cơ thể họ sẽ khó khắn trong việc sản xuất Insulin

* Lượng đường Glucose trong tập data chủ yếu trong khoảng 90 - 150 



#### The correlation between attributes and Outcome

*Cách tính đường hồi quy tuyến tính:*

* Tính tổng các bình phương khoảng cách d tới đường hồi quy sao cho là bé nhất với mọi điểm dữ liệu. Ta sẽ được đường hồi quy phù hợp nhất

$$
sum_{min} = d_1^2+d_2^2+d_3^2+... \\
$$

* Công thức tính khoảng cách từ 1 điểm đến 1 đường thẳng

$$
d(M, \Delta) = \sqrt{\dfrac{|ax_0+by_0+c|}{a^2+b^2}} \\
$$

```{r}
p1 <- ggplot(data = diabetes, aes(x = Glucose, y = Outcome)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Mối quan hệ giữa nồng độ glucose và kết quả bệnh tiểu đường",
       x = "Nồng độ glucose (mg/dL)",
       y = "Kết quả (1 = mắc bệnh, 0 = không mắc bệnh)")

p2 <- ggplot(data = diabetes, aes(x = SkinThickness, y = Outcome)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Mối quan hệ giữa độ dày của da và kết quả bệnh tiểu đường",
       x = "độ dày da (mm)",
       y = "Kết quả (1 = mắc bệnh, 0 = không mắc bệnh)")

p3 <- ggplot(data = diabetes, aes(x = Pregnancies, y = Outcome)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Mối quan hệ giữa số lần mang thai và kết quả bệnh tiểu đường",
       x = "Số lần mang thai (lần)",
       y = "Kết quả (1 = mắc bệnh, 0 = không mắc bệnh)")

grid.arrange(p1, p2, p3, ncol = 3)
```
<br> Ta có thể thấy

* Theo đường hồi quy tuyến tính dương trên, số lần mang thai hoặc nồng độ glucose càng tăng thì tỉ lệ mắc bệnh tiểu đường càng cao

* Ngược lại, độ dày của da không ảnh hưởng quá mạnh vào khả năng mắc bệnh tiểu đường



#### Kiểm tra giá trị rỗng

```{r}
sum_of_nan <- sum(is.na(diabetes))
paste("Tổng số giá trị rỗng trong dataset:", sum_of_nan)

for (col in colnames(diabetes)) {
  nan_of_col <- sum(is.na(diabetes[, col]))
  print(paste("Số giá trị rỗng trong cột", col, ":", nan_of_col))
}
```

#### Kiểm tra giá trị ngoại lai

##### Tìm giá trị ngoại lai

```{r}
find_outliers <- function(inp, na.rm = TRUE) {
  i.qnt <- quantile(inp, probs = c(0.25, 0.75), na.rm = na.rm)
  i.max <- 1.5 * IQR(inp, na.rm = na.rm)
  
  outliers <- inp < (i.qnt[1] - i.max) | inp > (i.qnt[2] + i.max)
  
  return(outliers)
}

```

##### Lập tỉ lệ outliers trong cột tương ứng

```{r}
calculate_rate <- function(inp) {
  num_outliers <- sum(find_outliers(inp))
  num_regular <- length(inp) - num_outliers
  
  outlier_rate <- num_outliers / length(inp) * 100
  regular_rate <- num_regular / length(inp) * 100
  
  rates <- list(outlier=outlier_rate, regular=regular_rate)
  return (rates)
}
```


```{r}
for (col in colnames(diabetes)) {
  rates <- calculate_rate(unlist(diabetes[, col]))
  # Liệt kê tỉ lệ giá trị ngoại lại trong từng cột
  print(paste(col, "-", "Total Outliers (%):", round(rates$outlier, 2), ", Regular Values (%):", round(rates$outlier, 2)))
}
```

##### Vẽ trực quan tỉ lệ ngoại lai

```{r}
pie_outlier <- function(outlier_col) {for (col in outlier_col) {
  rates <- calculate_rate(unlist(diabetes[, col]))
  
  pie_data <- data.frame(
    type = c("Outliers", "Regular"),
    rate = c(rates$outlier, rates$regular)
  )
  
  # Vẽ trực quan những cột có tỉ lệ ngoại lai >= 2.3%
  return(ggplot(pie_data, aes(x="", y = rate, fill=type)) +
  geom_bar(stat="identity", width=1, color="white") +
  coord_polar("y", start=0) +
  theme_void() +
  labs(title = paste(col),
     caption = paste0("Total Outliers (%):", round(rates$outlier, 2), ", Regular Values (%):", round(rates$regular, 2))))
}}
```

```{r}
grid.arrange(pie_outlier("BloodPressure"), pie_outlier("Insulin"), pie_outlier("BMI"), pie_outlier("DiabetesPedigreeFunction"), ncol=2)
```


#### Kiểm tra độ tương quan của các thuộc tính

```{r}
library(lattice)
library(reshape2)
```

```{r}
# creating correlation matrix
corr_mat <- round(cor(diabetes),2)
 
# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
# head(melted_corr_mat)
 
# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value)) + geom_tile() +
  geom_text(aes(Var2, Var1, label = value), color = "white", size = 4)
```
Ta có thể thấy:

* Tất cả thuộc tính đều có quan hệ thuận biến với Outcome (kết quả)

* Glucose, BMI và Age ảnh hưởng tới kết quả mắc bệnh lớn nhất với 0.47, 0.29, 0.24

* SkinThickness, BloodPressure ảnh hưởng tới kết quả mắc bệnh yếu nhất với 0.7



## II.Tiền xử lí dữ liệu

<h3>**Chuẩn bị các thư viện**</h3>

```{r}
#install.packages("readr")
#install.packages("dplyr")
#install.packages("tidyr")
#install.packages("ggplot2")
```

 
```{r}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
```


### Xử lí giá trị bị thiếu

####  Kiểm tra các giá trị bị thiếu 

*Kiểm tra các giá trị bị thiếu của từng cột*

```{r}
na_count<-colSums(sapply(diabetes,is.na))
na_count
```
*Bộ dữ liệu này không tồn tại giá trị bị thiếu*

#### Các phương pháp xử lí giá trị bị thiếu

*Giới thiệu 3 phương pháp xử lí giá trị bị thiếu :*

*Điền giá trị trung vị.*

```{r}
diabetes_median <- diabetes %>%
mutate_all(~ ifelse(is.na(.), median(., na.rm = TRUE), .))
```

*Điền giá trị trung bình.*

```{r}
diabetes_mean <- diabetes %>%
mutate_all(~ ifelse(is.na(.), mean(., na.rm = TRUE), .))
```

*Điền giá trị phổ biến nhất.*

```{r}

fill_mode <- function(x) {
  mode_val <- names(sort(table(x), decreasing = TRUE))[1] 
  x[is.na(x)] <- mode_val 
  return(x)
}

diabetes_mode <- diabetes %>%
mutate_all(fill_mode)


```

### Xử lí giá trị ngoại lai
#### Phương pháp xử lý giá trị ngoại lai dựa trên ma trận Z-score

*Bước 1:Tìm Z-score cho tất cả các điểm trong tập dữ liệu*

*Bước 2: Vẽ biểu đồ Scatter Plots biểu diễn ma trận Z-score*

*Bước 3: Quan sát biểu đồ Z-score,tìm Z-score ngưỡng*

*Bước 4: Dựa trên Z-score ngưỡng và loại các giá trị vượt qua Z-score ngưỡng đó*

#### *Ta có công thức như sau :*

$$
Z = \frac{{X - \bar{X}}}{{\sigma}}
$$

*Trong đó:*

-   $X$ là giá trị của một điểm dữ liệu cụ thể trong một thuộc tính nào đó.

-   $\bar{X}$ là giá trị trung bình của thuộc tính đó trong tập dữ liệu.

-   $\sigma$ là độ lệch chuẩn của thuộc tính đó trong tập dữ liệu.

*Áp dụng công thức trên để biến đổi bộ dữ liệu thành ma trận Z-score*

```{r}
diabetes_z <- (diabetes - colMeans(diabetes)) / apply(diabetes, 2, sd)
head(diabetes_z)

```

#### Vẽ biểu đồ Scatter Plots biểu diễn ma trận Z-score
*Biểu đồ này cho phép chúng ta quan sát được các giá trị ngoại lai*

```{r}

melted_diabetes <- gather(diabetes_z, key = "Variable", value = "Z-score")

# Vẽ scatter plot cho tất cả các cột
ggplot(melted_diabetes, aes(x = Variable, y = `Z-score`, color = `Z-score`)) +
  geom_point() +
  labs(x = "Variable", y = "Z-score", title = "Scatter Plots of Z-scores") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Điều chỉnh góc và vị trí của chú thích trên trục x
```

#### Quan sát biểu đồ ta thấy được các điểm Z-score >=700 là các giá trị ngoại lai 

*Ta chọn Z-score ngưỡng là 700 và loại các giá trị Z-score mà vượt qua ngưỡng đó * 

```{r}
# Lọc các giá trị Z-score mà tất cả đều nhỏ hơn 700
diabetes_filter <- diabetes[rowSums(apply(diabetes_z, 2, function(x) abs(x) < 700)) == ncol(diabetes_z), ]

# Hiển thị kích thước của bộ dữ liệu sau khi loại bỏ
cat("Còn lại số lượng hàng và cột là:", dim(diabetes_filter))
```

### Loại bỏ các cột không cần thiết (nếu có) cho việc xây dựng mô hình


#### Vẽ biểu đồ hộp để xem sự phân phối dữ liệu của biến mục tiêu và biến độc lập

```{r}
attach(diabetes_filter)
par(mfrow=c(2,4))
boxplot(Pregnancies~Outcome, main="No. of Pregnancies vs. Diabetes", 
        xlab="Outcome", ylab="Pregnancies",col="red")
boxplot(Glucose~Outcome, main="Glucose vs. Diabetes", 
        xlab="Outcome", ylab="Glucose",col="pink")
boxplot(BloodPressure~Outcome, main="Blood Pressure vs. Diabetes", 
        xlab="Outcome", ylab="Blood Pressure",col="green")
boxplot(SkinThickness~Outcome, main="Skin Thickness vs. Diabetes", 
        xlab="Outcome", ylab="Skin Thickness",col="orange")
boxplot(Insulin~Outcome, main="Insulin vs. Diabetes", 
        xlab="Outcome", ylab="Insulin",col="yellow")
boxplot(BMI~Outcome, main="BMI vs. Diabetes", 
        xlab="Outcome", ylab="BMI",col="purple")
boxplot(DiabetesPedigreeFunction~Outcome, main="Diabetes Pedigree Function vs. Diabetes", xlab="Outcome", ylab="DiabetesPedigreeFunction",col="lightgreen")
boxplot(Age~Outcome, main="Age vs. Diabetes", 
        xlab="Outcome", ylab="Age",col="lightblue")
box(which = "outer", lty = "solid")

diabetes_f<-diabetes_filter
```
#### Huyết áp và độ dày của da ít thay đổi với bệnh tiểu đường, chúng sẽ bị loại khỏi mô hình. Các biến khác ít nhiều cho thấy mối tương quan với bệnh tiểu đường nên sẽ được giữ nguyên 

```{r}
diabetes_f $BloodPressure <- NULL
diabetes_f $SkinThickness <- NULL

dim(diabetes_f)
```

### Chuẩn hoá dữ liệu 

#### Phương pháp chuẩn hoá dữ liệu bằng MinMax-Scaler

#### Mục đích

-   *Đảm bảo rằng các biến có thang đo đồng nhất.*

-   *Miền giá trị nằm trong Khoảng (0-1).*

-   *Giúp mô hình học tốt hơn.*

-   *Giảm ảnh hưởng của biên độ lớn giữa các biến.*

#### Công thức :

$$ \text{Scaled Value} = \frac{{X - \text{min}(X)}}{{\text{max}(X) - \text{min}(X)}} $$

```{r}
min_max_scaler <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

diabetes_scale <- as.data.frame(lapply(diabetes_f, min_max_scaler))
head(diabetes_scale)

```
## III.Xây dựng các mô hình 

### PREDICTING DIABETES using Logarithmic Regression model

#### Chia tập dữ liệu thành 2 phần , 70% tập dữ liệu để train, 30 tập dữ liệu để test

```{r}
train <- diabetes_scale [1:530,]
test <- diabetes_scale [531:760,]
model <-glm(Outcome ~.,family=binomial(link='logit'),data=train)
summary(model)
```

#### Với mức ý nghĩa là 0.05 ta thấy rằng ba thuộc tính phù hợp nhất, 'Glucose', 'BMI' và 'Pregnancies' có giá trị p thấp.Điều này cho thấy rằng các biến độc lập này ảnh hưởng đáng kể đến hiệu suất của mô hình hồi quy logistic trong dự đoán 'Kết quả.'

#### "Insulin" và "Age" không có ý nghĩa thống kê vì giá trị p cao .

```{r}
anova(model, test="Chisq")
```

#### Bảng "Analysis of Deviance Table" cung cấp thông tin về sự biến động của deviance (độ lệch) khi thêm vào từng biến độc lập vào mô hình

#### Chúng ta có thể thấy rằng việc bổ sung insulin và tuổi tác ít ảnh hưởng đến độ lệch

#### Với mức ý nghĩa 0,05 cho thấy rằng Pregnacies, Glucose, BMI là những yếu tố dự báo quan trọng của biến Kết quả.




### Cross Validation

#### Bắt đầu nhận dạng và chuyển đổi xác suất thành nhãn dự đoán 1: mắc bệnh,0: không mắc bệnh 
#### Tìm ma trận nhầm lẫn

```{r}
fitted.results <- predict(model,newdata=test,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
(conf_matrix_logi<-table(fitted.results, test$Outcome))

```

#### Tính toán độ chính xác toàn thể,độ nhạy,độ đặc hiệu

```{r}
TP <- conf_matrix_logi[2, 2]  # True Positive
TN <- conf_matrix_logi[1, 1]  # True Negative
FP <- conf_matrix_logi[1, 2]  # False Positive
FN <- conf_matrix_logi[2, 1]  # False Negative

Accuracy<-(TP+TN)/(TP+TN+FP+FN)
cat("Độ chính xác:",Accuracy,"\n")

#trong số bệnh nhân thực tế bị bệnh tiểu đường,bao nhiêu phần trăm được dự báo bị bệnh
Sensitivity<-TP/(TP+FN)
cat("Độ nhạy:",Sensitivity,"\n")
#trong số bệnh nhân thực tế không bị bệnh, bao nhiêu phần trăm được dự báo không bị bệnh

Specificity<-TN/(TN+FP)
cat("Độ đặc hiệu",Specificity)

```

#### Dựa trên các con số này. Ta thể kết luận rằng mô hình có độ chính xác khá cao. Đối với việc dự đoán bệnh nhân bị bệnh tiểu đường, mô hình có độ nhạy là 73.77%, và đối với việc dự đoán bệnh nhân không bị bệnh tiểu đường, độ đặc hiệu là 80.47%. Điều này cung cấp cái nhìn chi tiết hơn về hiệu suất của mô hình trong từng khía cạnh cụ thể

### PREDICTING DIABETES using Decision Tree model

#### Ma trận tương quan

```{r}
#install.packages("corrgram")
library(corrgram)
```

```{r}
corrgram(diabetes_filter)
```

Xét biểu đồ tương quan, ta thấy:<br> - Pregnancies và Age tương quan
cao<br> - SkinThickness và Insulin tương quan cao<br>

Do đó: Khi xây dựng mô hình dự đoán, với mỗi cặp thuộc tính, chỉ sử dụng
1 trong 2 để hạn chế tình trạng đa cộng tuyến (multicollinearity)


### MÔ HÌNH CÂY QUYẾT ĐỊNH
#### Chia tập dữ liệu thành 2 tập train và test

```{r}
library(caret)
```

Chi tập dữ liệu thành 2 phần, tập train để xây dựng mô hình và tập test để kiểm tra mô hình
```{r}
set.seed(1)
split <- createDataPartition(diabetes_filter$Outcome,p = 0.75,list = FALSE)
dfTrain <- diabetes_filter[split,]
dfTest <- diabetes_filter[-split,]
```

```{r}
head(dfTrain)
```

```{r}
head(dfTest)
```

#### Hàm kiểm tra mô hình
Xây dựng các hàm kiểm tra kết quả của mô hình

Hàm xây dựng ma trận nhầm lẫn để xem kết quả dự đoán và tính độ chính xác bằng ma trận nhầm lẫn
```{r}
# Dùng ma trận nhầm lẫn
accuracy <- function() {
  predictions <- predict(model, newdata = dfTest, type = "class")
  
  # So sánh giữa giá trị dự đoán và giá trị thực tế
  confusion_matrix <- table(predictions, dfTest$Outcome)
  print(confusion_matrix)
  
  # Tính toán độ chính xác từ ma trận nhầm lẫn
  accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
  return (accuracy)
}
```


Hàm tính độ chính xác, độ nhạy và độ đặc hiệu của mô hình
```{r}
thongso <- function() {
  predictions <- predict(model, newdata = dfTest, type = "class")
  confusion_matrix <- table(predictions, dfTest$Outcome)
  TP <- confusion_matrix[2, 2]  # True Positive
  TN <- confusion_matrix[1, 1]  # True Negative
  FP <- confusion_matrix[1, 2]  # False Positive
  FN <- confusion_matrix[2, 1]  # False Negative
  
  Accuracy<-(TP+TN)/(TP+TN+FP+FN)
  cat("Độ chính xác:",Accuracy,"\n")
  
  #trong số bệnh nhân thực tế bị bệnh tiểu đường,bao nhiêu phần trăm được dự báo bị bệnh
  Sensitivity<-TP/(TP+FN)
  cat("Độ nhạy:",Sensitivity,"\n")
  #trong số bệnh nhân thực tế không bị bệnh, bao nhiêu phần trăm được dự báo không bị bệnh
  
  Specificity<-TN/(TN+FP)
  cat("Độ đặc hiệu",Specificity)
}
```


#### Xây dựng mô hình cây quyết định 
##### Mô hình cây quyết định
Xây dựng mô hình cây quyết định ban đầu. Với thuộc tính mục tiêu là Outcome, và biến thành phần và các thuộc tính còn lại của tập dữ liệu
```{r}
# Huấn luyện mô hình cây quyết định
library(rpart)
model <- rpart(Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age, data = dfTrain, method = "class")

# In cây quyết định
print(model)

# Biểu đồ cây quyết định
library(rpart.plot)
rpart.plot(model)
```
<br>Xem kết quả dự đoán từ mô hình cây quyết định
```{r}
thongso()
```


##### Xem độ quan trọng của các thuộc tính trong mô hình
Quan sát biểu đồ mức độ quan trọng của các thuộc tính trong mô hình để thay đổi thuộc tính thành phần
```{r}
library(vip)
var_importance <- vip::vip(model, num_features = 10)
print(var_importance)
```

Quan sát tác động của của các thuộc tính riêng lẻ lên quyết định của mô hình
```{r}
library(pdp)
library(ggplot2)

# Lặp qua từng cột trong dfTrain (loại bỏ cột mục tiêu)
for (col in names(dfTrain)[-ncol(dfTrain)]) {
  # Tạo Partial Dependence Plot cho từng cột và lưu vào biến pdp_plot
  pdp_plot <- partial(model, pred.var = col)
  
  # Tạo biểu đồ Partial Dependence Plot và hiển thị
  plot(pdp_plot, main = paste("Partial Dependence Plot for", col))
}

```

<br>Dựa vào biểu đồ mức độ quan trọng của các thuộc tính trong mô hình ta thấy rằng: <br>
  - Các thuộc tính Pregnancies, BloodPressure, SkinThickness, Insulin có trọng số thấp nhất. <br>
Dựa vào Partial Dependence Plot (PDP) - Biểu đồ phụ thuộc một phần thấy rằng:<br>
  - Các thuộc tính Pregnancies, BloodPressure, SkinThickness, Insulin tăng lên nhưng không ảnh hưởng đến kết quả dự đoán của mô hình.<br>
  
##### Loại bỏ các thuộc tính trên (Pregnancies, SkinThickness, Insulin)
Loại bỏ thuộc tính Insulin, SkinThickness và Pregnancies thấy mô hình tăng độ chính xác, độ nhạy và độ đặc hiệu. Quyết định chấp nhận mô hình với độ chính xác ~76% và độ nhạy ~0.64, độ đặc hiệu ~0.82

```{r}
model <- rpart(Outcome ~ Glucose + BloodPressure + BMI + DiabetesPedigreeFunction + Age, data = dfTrain, method = "class")
rpart.plot(model)
```
<br>Thông số của mô hình sau khi loại bỏ các thuộc tính có độ quan trọng thấp
```{r}
accuracy()
thongso()
```

##### Trích xuất các luật từ cây quyết định
Xem quy luật của mô hình cây quyết định
```{r}
rules <- rpart.rules(model)
print(rules)
```
#### So sánh hiệu suất của mô hình hồi quy logistic với mô hình cây quyết định ta thấy :
-> *Hai mô hình cho thấy độ chính xác và độ đặc hiệu khá giống nhau *
-> *Nhưng độ nhạy lại khác nhau.Mô hình hồi quy logistic có độ nhạy lớn hơn cho thấy mô hình nhận dạng các trường hợp bị bệnh chính xác hơn*

-> *Đối với các bài toán dự báo bệnh thì độ nhạy lớn sẽ tốt hơn. Điều này là do độ nhạy là thước đo về mức độ tốt của mô hình trong việc dự đoán các trường hợp dương tính. Trong các bài toán dự báo bệnh, việc xác định chính xác các trường hợp mắc bệnh là rất quan trọng. Nếu mô hình có độ nhạy thấp, thì mô hình sẽ có xu hướng bỏ sót các trường hợp mắc bệnh, điều này có thể dẫn đến việc điều trị sai hoặc không điều trị. *

### Classifying the categories of Mass (BMI) using Random Forest model

The World Health Organization (WHO) classifies adults based on the
following BMI ranges:

-   Underweight: \< 18.5 kg/m\^2

-   Normal weight: 18.5 - 24.9 kg/m\^2

-   Overweight: 25.0 - 29.9 kg/m\^2

-   Obese: ≥ 30.0 kg/m\^2

```{r}
library(ggplot2)
```

```{r}
diabetes_filter$BMI_Category <- cut(diabetes_filter$BMI, 
                             breaks = c(-Inf, 18.5, 24.9, 29.9, Inf), 
                             labels = c("Underweight", "Normal", "Overweight", "Obese"))
```

*Trực quan phân bố của từng loại cân nặng*

```{r}
ggplot(diabetes_filter, aes(x = BMI_Category)) + 
  geom_bar(stat = "count") +
  labs(title = "Distribution of BMI Categories", x = "BMI Category", y = "Count") +
  theme_bw()

```

*Tạo một dataframe bản sao với BMI_Category đã được số hóa*

```{r}
num_diabetes <- diabetes_filter
num_diabetes$BMI_Category <- as.integer(num_diabetes$BMI_Category)
str(num_diabetes)
```

*Tìm các biến độc lập so với biến phụ thuộc BMI_Category*

```{r}
library(lattice)
library(reshape2)

# creating correlation matrix
corr_mat <- round(cor(num_diabetes),2)

# reduce the size of correlation matrix
melted_corr_mat <- melt(corr_mat)
# head(melted_corr_mat)

# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value)) + geom_tile() +
  geom_text(aes(Var2, Var1, label = value), color = "white", size = 4)
```

Ta có thể thấy:

-   So với BMI_Category, các thuộc tính BMI, Insulin, SkinThickness,
    BloodPressure và Glucose đều tương quan mạnh (5 thuộc tính)

-   Vậy thuộc tính BMI_Category sẽ phụ thuộc nhiều vào chúng, ta có thể
    xem chúng là các biến độc lập

## **Xây mô hình Random Forest để phân loại cân nặng**

### Chia dữ liệu thành huấn luyện và kiểm tra. 70% dành cho huấn luyện, 30% dành cho kiểm tra.

```{r}
set.seed(456)

samp <- sample(nrow(diabetes_filter), 0.7 * nrow(diabetes_filter))

train <- diabetes_filter[samp, ]

test <- diabetes_filter[-samp, ]
```

```{r}
#Kiểm tra kích thước của tập dữ liệu huấn luyện và kiểm tra
str(train)
```

```{r}
library(randomForest) 
```

### Tìm giá trị tốt nhất cho tham số mtry bằng tuneRF

```{r}
rf_fit <- tuneRF(
  x = train[, 1:8],
  y = train[, 10],
  metric = "OOBAcc",
  ntreeTry = 100,
  mtryStart = 3,
  stepFactor = 1.5,
  improve = 0.01,
  trace = T,
  plot = T
)
```

### Tìm số cây trong rừng để mô hình cho kết quả tốt nhất với mtry = 3

```{r}
# Lặp lại quá trình huấn luyện và đánh giá trên các giá trị khác nhau của ntree
error_out_of_bag <- c()

for (ntree in 1:100) {
    # Huấn luyện mô hình
    model <- randomForest(BMI_Category ~ . -Age -Pregnancies, data = train, ntree = ntree, mtry=3)
    
    # Tạo tập oob
    oob <- sample(nrow(train), 0.3 * nrow(train))
    
    # Tính lỗi out_of_bag
    error_out_of_bag[ntree] <- mean(predict(model, train[oob,]) != train[oob,]$BMI_Category)
}

# Vẽ đường cong lỗi
plot(error_out_of_bag, type = "l", col = "red", ylab = "OOB error", xlab="Số cây trong rừng")
```

### Huấn luyện mô hình

```{r}
model <- randomForest(BMI_Category ~ . -Age -Pregnancies, data = train, ntree = 100, mtry=3)
model
```

Ta có thể thấy:

* OOB error tỉ lệ số lần phân loại sai trên tập OOB ở các cây trong rừng, OOB error càng thấp thì độ chính xác càng cao

* class error là tỉ lệ phân loại sai ở các nhãn trên tập train đã tách OOB

* Các chỉ số trên có thể khác nhau ở mỗi lần train, vì tập OOB sẽ lấy ngẫu nhiên


### Xác thực mô hình của chúng tôi bằng cách sử dụng dữ liệu thử nghiệm

```{r}
prediction_test <- predict(model, newdata = test)
prediction_train <- predict(model, newdata = train)

table(prediction_train, train$BMI_Category)
table(prediction_test, test$BMI_Category)
```

### Hiển thị giá trị dự đoán so với giá trị thực tế

```{r}
results<-cbind(prediction_test, test$BMI_Category)

head(results)
```

```{r}
colnames(results)<-c('pred','real')

results<-as.data.frame(results)

View(results)
```

### Tính độ chính xác của mô hình

```{r}
accuracy_test <- mean(prediction_test == test$BMI_Category)
accuracy_train <- mean(prediction_train == train$BMI_Category)

paste("độ chính xác trên tập train: ", accuracy_train)
paste("độ chính xác trên tập test: ", accuracy_test)
```

Bạn có thể thấy rằng độ chính xác của mô hình này là khoảng 99-100 (%), điều này thật tuyệt vời. Bây giờ chúng tôi đã tự động hóa quá trình dự đoán loại cân nặng. Điều này đưa chúng ta đến khả năng theo dõi tình trạng sức khỏa của bệnh nhân và đưa ra chuẩn đoán sớm


## **kiểm định giả thuyết thống kế**

### để chứng minh phần trăm mỡ trong cơ thẻ cũng ảnh hướng đến việc có mắc bệnh hay không

### *Cách 1: One-Sample T-test*

### giả thuyết BMI (Chỉ số khối cơ thể) trung bình 34 dễ mắc bệnh tiểu đường

```{r}
library(knitr)
```

```{r}
# Vẽ biểu đồ histogram
ggplot(diabetes_filter, aes(x = BMI)) +
  geom_histogram(binwidth = 2, fill = "lightblue", color = "black") + 
  labs(x = "BMI", title = "Histogram of BMI") + theme_minimal() 

# summary statistics
kable(summary(select(diabetes_filter, BMI)), format = "markdown")
```

### Giả thuyết BMI trung bình mắc bệnh tiểu đường là 34

$$ 
H_0: bmi = 34
$$ 

$$ 
H_a: bmi \neq 34
$$

$$
t = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} \\
\bar{x} \text{: là giá trị trung bình của mẫu.} \\
\mu_0 \text{: là giá trị trung bình đã biết đến hoặc giả định.} \\
s \text{: là độ lệch chuẩn của mẫu.} \\
n \text{: là kích thước mẫu.} \\
$$

```{r}
# Tính độ lệch chuẩn của mẫu dữ liệu
standard_deviation <- sd(diabetes_filter$BMI)
print(standard_deviation)

t.test(num_diabetes[num_diabetes$Outcome==1,6], mu=34)
```

#### Kết luận và giải thích

-   Từ đầu ra và từ p.value chúng ta thấy rằng
-   p-value nhỏ mức ý nghĩa 5%.
-   Giống như bất kỳ bài kiểm tra thống kê nào khác , nếu p-value nhỏ
    hơn mức ý nghĩa thì có thể bác bỏ giả thuyết. --\> Dựa vào kết quả
    kiểm định t-test, có thể kết luận rằng giá trị trung bình thực sự
    của cột "BMI" không bằng 34, và Ước lượng trung bình của mẫu có thể
    nằm trong khoảng từ 34.21895 đến 35.98862 với mức tin cậy 95%.

# -------------------------------------------

## **Cách 2: Independent Samples T-test**

#### **để chứng minh phần trăm mỡ trong cơ thẻ cũng ảnh hướng đến việc có mắc bệnh hay không**

### giả thuyết lượng mỡ trong cơ thể (BMI) không ảnh hưởng đến việc có bệnh hay không\*\*

```{r}
# Vẽ biểu đồ histogram
ggplot(diabetes_filter, aes(x = BMI_Category)) + 
  geom_bar(stat = "count") + 
  labs(title = "Distribution of BMI Categories", x = "BMI Category", y = "Count") + 
  theme_bw()
```

### Giả thuyết tỳ lệ BMI của người bệnh và không bệnh là như nhau 
$$ 
H_0: bmi_0 = bmi_1
$$ 

$$ 
H_a: bmi_0 \neq bmi_1
$$



$$
t = \frac{\bar{x}_A - \bar{x}_B}{\sqrt{\frac{s_A^2}{n_A} + \frac{s_B^2}{n_B}}} \\
(\bar{x}_A) \text{: là giá trị trung bình của nhóm A.} \\
(\bar{x}_B) \text{: là giá trị trung bình của nhóm B.} \\
(s_A) \text{: là độ lệch chuẩn của nhóm A.} \\
(s_B) \text{: là độ lệch chuẩn của nhóm B.} \\
(n_A) \text{: là kích thước của nhóm A.} \\
(n_B) \text{: là kích thước của nhóm B.} \\
$$



```{r}
#lấy ra những người bệnh và không bệnh có chỉ số BMI_Category >= 3
sick <- num_diabetes[num_diabetes$Outcome==1 & num_diabetes$BMI_Category >= 3,6]
normal <- num_diabetes[num_diabetes$Outcome==0 & num_diabetes$BMI_Category >= 3,6]
length(sick)
length(normal)
# Tính độ lệch chuẩn của mỗi mẫu dữ liệu
sa <- sd(sick)
print(sa)

sb <- sd(normal)
print(sb)
```

```{r}
# Kiểm tra đồng nhất về phương sai
result <- var.test(sick, normal)
print(result)
```

```{r}
t.test(normal,sick,var.equal=FALSE)
```
#### Kết luận và giải thích

-   Từ đầu ra và từ p.value chúng ta thấy rằng
-   p-value nhỏ hơn mức ý nghĩa 5%.
-   Giống như bất kỳ bài kiểm tra thống kê nào khác , nếu p-value nhỏ
    hơn mức ý nghĩa thì có thể bác bỏ giả thuyết. --\> Dựa vào kết quả
    kiểm định t-test, có thể kết luận rằng lượng mỡ trong cơ thể có ảnh
    hưởng đến việc người đó có bệnh tiểu đường .

## *để chứng minh độ tuổi cũng ảnh hưởng đến việc người đó có bị bệnh tiểu đường hay không.*

### giả thuyết độ tuổi trung bình mắc bệnh tiểu đường là 35

```{r}
# Vẽ biểu đồ histogram
ggplot(num_diabetes, aes(x = Age)) +
  geom_histogram(binwidth = 2, fill = "lightblue", color = "black") +
  labs(x = "Age", title = "Histogram of Age") +
  theme_minimal()

# summary statistics
kable(summary(select(diabetes, Age)), format = "markdown")
```

###giả thuyết độ tuổi trung bình mắc bệnh tiểu đường là 35

$$ 
H_0: age = 35
$$

$$ 
H_a: age \neq 35
$$

```{r}
t.test(num_diabetes[num_diabetes$Outcome==1,8], mu=35)
```

#### Kết luận và giải thích

-   Từ đầu ra và từ p.value chúng ta thấy rằng
-   p-value nhỏ mức ý nghĩa 5%.
-   Giống như bất kỳ bài kiểm tra thống kê nào khác , nếu p-value nhỏ
    hơn mức ý nghĩa thì có thể bác bỏ giả thuyết không. --\> Dựa vào kết
    quả kiểm định t-test, có thể kết luận rằng giá trị trung bình thực
    sự của cột "Age" không bằng 35, và Ước lượng trung bình của mẫu có
    thể nằm trong khoảng từ 35.80157 đến 38.46359 với mức tin cậy 95%.
